{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from charRNN_utils import parseFile,buildModel, generateSequence,plotGraph\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Setting - Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_prevChar = 50\n",
    "datapath = '/home/adityav/UCSD/Spring17/COGS260_ImageRecognition/HW4/Data/tinyshakespeare.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[trainData,testData, vocab, vocabLength, seedList] = parseFile(datapath,num_prevChar, batchIndex = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building model.......................................\n",
      "Model Build.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 256)               329728    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 65)                16705     \n",
      "=================================================================\n",
      "Total params: 346,433\n",
      "Trainable params: 346,433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nHiddenNeuron = 256\n",
    "percentDropout = 0\n",
    "optimizerList = ['RMSprop','Adagrad']\n",
    "optimizerUsed = optimizerList[1]\n",
    "rnn_lstm = 'lstm'           # 'rnn' or 'lstm' -> depends on the type of cell we want to use in network.\n",
    "\n",
    "model = buildModel(num_prevChar ,vocabLength,\n",
    "                   nHiddenNeuron, rnn_lstm,\n",
    "                   percentDropout,optimizerUsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adityav/.virtualenvs/cv/local/lib/python2.7/site-packages/keras/models.py:837: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 111533 samples, validate on 27884 samples\n",
      "Epoch 1/2\n",
      " 64512/111533 [================>.............] - ETA: 213s - loss: 13.5184 - acc: 0.0453"
     ]
    }
   ],
   "source": [
    "for batchIndex in range(8):\n",
    "    [trainData,testData, vocab, vocabLength, seedList] = parseFile(datapath,num_prevChar, batchIndex = 1)\n",
    "    history = model.fit(trainData['x'],trainData['y_true'],\n",
    "                        batch_size=1024, nb_epoch=2,verbose=1,\n",
    "                        validation_data=( testData['x'], testData['y_true']))\n",
    "model.save_weights('charRNN_model_weights.hdf5')\n",
    "plotGraph(history, percentDropout, nHiddenNeuron, optimizerUsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxLength = 1000; \n",
    "#seedIndex = [83,19,51,27,17,19]\n",
    "count = 1\n",
    "\n",
    "fHandle = open('GeneratedShakespeare.txt','w')\n",
    "\n",
    "for i in range(1):\n",
    "    seedIndex = random.randint(0,len(seedList)-1)\n",
    "    seedSentence = seedList[seedIndex]\n",
    "    generateSequence(fHandle, model, num_prevChar, vocabLength, vocab,\n",
    "                     maxLength,seedSentence, count)\n",
    "    count = count+1\n",
    "\n",
    "fHandle.close()\n",
    "\n",
    "print('Generated  shakespeare File: GeneratedShakespeare.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
